{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b0e8e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier, RandomForestRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "671093c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>source_r</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>3662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>2900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3883</td>\n",
       "      <td>3914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   US  source_a  source_c  source_b  source_d  source_e  source_m  source_o  \\\n",
       "0   1         0         0         1         0         0         0         0   \n",
       "1   1         0         0         0         0         1         0         0   \n",
       "2   1         0         0         0         0         0         0         0   \n",
       "3   1         0         1         0         0         0         0         0   \n",
       "4   1         0         1         0         0         0         0         0   \n",
       "\n",
       "   source_h  source_r  ...  source_x  source_w  Freq  last_update_days_ago  \\\n",
       "0         0         0  ...         0         0     2                  3662   \n",
       "1         0         0  ...         0         0     0                  2900   \n",
       "2         0         0  ...         0         0     2                  3883   \n",
       "3         0         0  ...         0         0     1                   829   \n",
       "4         0         0  ...         0         0     1                   869   \n",
       "\n",
       "   1st_update_days_ago  Web order  Gender=male  Address_is_res  Purchase  \\\n",
       "0                 3662          1            0               1         1   \n",
       "1                 2900          1            1               0         0   \n",
       "2                 3914          0            0               0         1   \n",
       "3                  829          0            1               0         0   \n",
       "4                  869          0            0               0         0   \n",
       "\n",
       "   Spending  \n",
       "0    127.87  \n",
       "1      0.00  \n",
       "2    127.48  \n",
       "3      0.00  \n",
       "4      0.00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('HW3.xlsx')\n",
    "data.drop('sequence_number', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada12018",
   "metadata": {},
   "source": [
    "# Exploratory Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "065f0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the data set are 2000 by 24\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = data.shape\n",
    "print('The dimensions of the data set are', n_samples, 'by', n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ecd47df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>source_r</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1.417000</td>\n",
       "      <td>2155.101000</td>\n",
       "      <td>2435.601500</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>102.560745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.380489</td>\n",
       "      <td>0.332495</td>\n",
       "      <td>0.229979</td>\n",
       "      <td>0.237546</td>\n",
       "      <td>0.199493</td>\n",
       "      <td>0.358138</td>\n",
       "      <td>0.12742</td>\n",
       "      <td>0.179983</td>\n",
       "      <td>0.223089</td>\n",
       "      <td>0.252665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>1.405738</td>\n",
       "      <td>1141.302846</td>\n",
       "      <td>1077.872233</td>\n",
       "      <td>0.494617</td>\n",
       "      <td>0.499524</td>\n",
       "      <td>0.415024</td>\n",
       "      <td>0.500125</td>\n",
       "      <td>186.749816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "      <td>1671.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2280.000000</td>\n",
       "      <td>2721.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3139.250000</td>\n",
       "      <td>3353.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1500.060000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                US     source_a     source_c     source_b     source_d  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.824500     0.126500     0.056000     0.060000     0.041500   \n",
       "std       0.380489     0.332495     0.229979     0.237546     0.199493   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          source_e    source_m     source_o     source_h     source_r  ...  \\\n",
       "count  2000.000000  2000.00000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.151000     0.01650     0.033500     0.052500     0.068500  ...   \n",
       "std       0.358138     0.12742     0.179983     0.223089     0.252665  ...   \n",
       "min       0.000000     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.00000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "          source_x     source_w         Freq  last_update_days_ago  \\\n",
       "count  2000.000000  2000.000000  2000.000000           2000.000000   \n",
       "mean      0.018000     0.137500     1.417000           2155.101000   \n",
       "std       0.132984     0.344461     1.405738           1141.302846   \n",
       "min       0.000000     0.000000     0.000000              1.000000   \n",
       "25%       0.000000     0.000000     1.000000           1133.000000   \n",
       "50%       0.000000     0.000000     1.000000           2280.000000   \n",
       "75%       0.000000     0.000000     2.000000           3139.250000   \n",
       "max       1.000000     1.000000    15.000000           4188.000000   \n",
       "\n",
       "       1st_update_days_ago    Web order  Gender=male  Address_is_res  \\\n",
       "count          2000.000000  2000.000000  2000.000000     2000.000000   \n",
       "mean           2435.601500     0.426000     0.524500        0.221000   \n",
       "std            1077.872233     0.494617     0.499524        0.415024   \n",
       "min               1.000000     0.000000     0.000000        0.000000   \n",
       "25%            1671.250000     0.000000     0.000000        0.000000   \n",
       "50%            2721.000000     0.000000     1.000000        0.000000   \n",
       "75%            3353.000000     1.000000     1.000000        0.000000   \n",
       "max            4188.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "          Purchase     Spending  \n",
       "count  2000.000000  2000.000000  \n",
       "mean      0.500000   102.560745  \n",
       "std       0.500125   186.749816  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.500000     1.855000  \n",
       "75%       1.000000   152.532500  \n",
       "max       1.000000  1500.060000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4b0f95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Purchase', 'Spending'], axis=1)\n",
    "y = data[['Spending']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e5709495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "cate_col = ['US', 'source_a', 'source_c', 'source_b', 'source_d', 'source_e','source_m', 'source_o', 'source_h', 'source_r', 'source_s', 'source_t',\n",
    "'source_u', 'source_p', 'source_x', 'source_w', 'Web order','Gender=male', 'Address_is_res']\n",
    "\n",
    "# numeric\n",
    "num_col = [\"Freq\", \"last_update_days_ago\", \"1st_update_days_ago\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ae63b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X[num_col])\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "626f5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def score():\n",
    "    return make_scorer(MSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de7aa5",
   "metadata": {},
   "source": [
    "# (a) All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f3712d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0bea7c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train[num_col] = scaler.fit_transform(X_train[num_col])\n",
    "X_test[num_col] = scaler.transform(X_test[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "27983e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasted cross-validation\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610f192",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0fcc860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'l1_ratio': 0.9}\n",
      "rmse:  129.70808513797073\n"
     ]
    }
   ],
   "source": [
    "lr = ElasticNet(random_state = 42)\n",
    "ratio = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lr_grid = {'l1_ratio':ratio}\n",
    "         \n",
    "lr_clf = GridSearchCV(estimator=lr, param_grid=lr_grid, cv=inner_cv, scoring=score())\n",
    "lr_pred = lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', lr_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-lr_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183a471",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb022a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "rmse:  130.34266644849652\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "k_values = list(range(1, 30))\n",
    "k_grid = {'weights': weights, 'n_neighbors': k_values}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn_clf = GridSearchCV(knn, k_grid, cv=inner_cv, scoring=score())\n",
    "knn_pred = knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', knn_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-knn_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8df6e",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d70d06ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'max_depth': 6, 'min_samples_split': 3}\n",
      "rmse:  136.17687782999906\n"
     ]
    }
   ],
   "source": [
    "depth = list(range(1, 10))  # max_depth\n",
    "split = list(range(2, 10))  # min_samples_split\n",
    "rt_grid = {'max_depth': depth, 'min_samples_split': split}\n",
    "\n",
    "rt = DecisionTreeRegressor()\n",
    "rt_clf = GridSearchCV(rt, rt_grid, cv=inner_cv, scoring=score())\n",
    "rt_pred = rt_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', rt_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-rt_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02850eb4",
   "metadata": {},
   "source": [
    "## SVM regreesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "96cff932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'kernel': 'rbf', 'gamma': 'auto', 'C': 1000}\n",
      "rmse:  125.77035848660468\n"
     ]
    }
   ],
   "source": [
    "kernal = ['rbf']\n",
    "gamma = ['scale', 'auto']\n",
    "c = [10 ** i for i in range(-2, 4)] \n",
    "svr_grid = {'kernel': kernal, 'C' : c, 'gamma' : gamma }\n",
    "\n",
    "svr = SVR()\n",
    "svr_clf = RandomizedSearchCV(svr, param_distributions=svr_grid, n_iter=20, cv=inner_cv, scoring=score(), random_state=42)\n",
    "svr_pred = svr_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', svr_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-svr_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14b0ad",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9e18ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nb_hidden, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_hidden, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "act = ['relu', 'tanh']\n",
    "hidden = np.array([64, 128, 256])\n",
    "epoch = list(range(3, 10))\n",
    "NN_grid = {'activation': act, 'nb_hidden': hidden, 'epochs': epoch}\n",
    "\n",
    "NN = KerasRegressor(build_fn=create_model, batch_size=256, verbose=0, nb_hidden=64, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7cacc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2cf5f3ec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2cf5f31a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "best params:  {'activation': 'tanh', 'epochs': 9, 'nb_hidden': 256}\n",
      "rmse: 211.34970411701931\n"
     ]
    }
   ],
   "source": [
    "NN_clf = GridSearchCV(estimator=NN, param_grid=NN_grid, scoring = score(), cv=5)\n",
    "NN_pred=NN_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', NN_pred.best_params_)\n",
    "print('rmse:' , np.sqrt(-NN_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfe225",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5aba3e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'final_estimator__min_samples_split': 8, 'final_estimator__max_depth': 3}\n",
      "rmse: 124.73319989419122\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('linear regression', ElasticNet(l1_ratio=0.9)),\n",
    "    ('regression tree', DecisionTreeRegressor(max_depth=6, min_samples_split=9)),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=8, weights='uniform')),\n",
    "    ('svr', SVR(C=100, gamma='auto', kernel='rbf'))\n",
    "]\n",
    "\n",
    "meta_model = RandomForestRegressor()\n",
    "\n",
    "srlf = StackingRegressor(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "grid = {'final_estimator__max_depth': list(range(1, 10)), 'final_estimator__min_samples_split': list(range(2, 10))}\n",
    "\n",
    "search = RandomizedSearchCV(srlf, grid, n_iter=20, cv=inner_cv, scoring=score(), random_state=42)\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', result.best_params_)\n",
    "print('rmse:', np.sqrt(-result.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d3eff",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af96927",
   "metadata": {},
   "source": [
    "\"Stack\" has the lowest RMSE (133.83), which suggests that the stacking ensemble model has the best overall performance among the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bc308043",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = cross_val_score(lr_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "knn_score = cross_val_score(knn_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "rt_score = cross_val_score(rt_clf , X=X_normalized, y=y, cv=outer_cv)\n",
    "svm_score = cross_val_score(svr_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "stack_score = cross_val_score(search, X=X_normalized, y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "84daea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear regression': 135.2529179706996,\n",
       " 'KNN': 135.86246033304639,\n",
       " 'Regression tree': 140.4184178864601,\n",
       " 'SVR': 139.6390532210261,\n",
       " 'Stack': 133.83387523437838}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "score['linear regression'] = np.sqrt(-lr_score).mean()\n",
    "score['KNN'] = np.sqrt(-knn_score).mean()\n",
    "score['Regression tree'] = np.sqrt(-rt_score).mean()\n",
    "score['SVR'] = np.sqrt(-svm_score).mean()\n",
    "score['Stack'] = np.sqrt(-stack_score).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4fce50",
   "metadata": {},
   "source": [
    "# (b): Purchase = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "77c4a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = data[data['Purchase'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dd09348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_b.drop(['Spending','Purchase'],axis=1)\n",
    "y = data_b[['Spending']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dc3b0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "cate_col = ['US', 'source_a', 'source_c', 'source_b', 'source_d', 'source_e','source_m', 'source_o', 'source_h', 'source_r', 'source_s', 'source_t',\n",
    "'source_u', 'source_p', 'source_x', 'source_w', 'Web order','Gender=male', 'Address_is_res']\n",
    "\n",
    "# numeric\n",
    "num_col = [\"Freq\", \"last_update_days_ago\", \"1st_update_days_ago\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5e01b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X[num_col])\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "605424da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "99a15bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train[num_col] = scaler.fit_transform(X_train[num_col])\n",
    "X_test[num_col] = scaler.transform(X_test[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c7d6b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasted cross-validation\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c1167",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6cffa760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def score():\n",
    "    return make_scorer(MSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcb82b",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1546eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'l1_ratio': 0.9}\n",
      "rmse:  160.6944881454774\n"
     ]
    }
   ],
   "source": [
    "lr = ElasticNet(random_state = 42)\n",
    "ratio = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lr_grid = {'l1_ratio':ratio}\n",
    "         \n",
    "lr_clf = GridSearchCV(estimator=lr, param_grid=lr_grid, cv=inner_cv, scoring=score())\n",
    "lr_pred = lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', lr_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-lr_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b91068",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "45895b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'n_neighbors': 9, 'weights': 'distance'}\n",
      "rmse:  163.19243730160628\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "k_values = list(range(1, 30))\n",
    "k_grid = {'weights': weights, 'n_neighbors': k_values}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn_clf = GridSearchCV(knn, k_grid, cv=inner_cv, scoring=score())\n",
    "knn_pred = knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', knn_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-knn_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb652508",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c8ac16ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'max_depth': 3, 'min_samples_split': 2}\n",
      "rmse:  169.76163685923171\n"
     ]
    }
   ],
   "source": [
    "depth = list(range(1, 10))  # max_depth\n",
    "split = list(range(2, 10))  # min_samples_split\n",
    "rt_grid = {'max_depth': depth, 'min_samples_split': split}\n",
    "\n",
    "rt = DecisionTreeRegressor()\n",
    "rt_clf = GridSearchCV(rt, rt_grid, cv=inner_cv, scoring=score())\n",
    "rt_pred = rt_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', rt_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-rt_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6342bc6",
   "metadata": {},
   "source": [
    "## SVM regreesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ac39e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'kernel': 'rbf', 'gamma': 'auto', 'C': 1000}\n",
      "rmse:  154.29887358848418\n"
     ]
    }
   ],
   "source": [
    "kernal = ['rbf']\n",
    "gamma = ['scale', 'auto']\n",
    "c = [10 ** i for i in range(-2, 4)] \n",
    "svr_grid = {'kernel': kernal, 'C' : c, 'gamma' : gamma }\n",
    "\n",
    "svr = SVR()\n",
    "svr_clf = RandomizedSearchCV(svr, param_distributions=svr_grid, n_iter=20, cv=inner_cv, scoring=score(), random_state=42)\n",
    "svr_pred = svr_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', svr_pred.best_params_)\n",
    "print('rmse: ', np.sqrt(-svr_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3aafb",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "09902562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'final_estimator__min_samples_split': 6, 'final_estimator__max_depth': 2}\n",
      "rmse: 162.9214252528662\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('linear regression', ElasticNet(l1_ratio=0.9)),\n",
    "    ('regression tree', DecisionTreeRegressor(max_depth=6, min_samples_split=9)),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=8, weights='uniform')),\n",
    "    ('svr', SVR(C=100, gamma='auto', kernel='rbf'))\n",
    "]\n",
    "\n",
    "meta_model = RandomForestRegressor()\n",
    "\n",
    "srlf = StackingRegressor(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "grid = {'final_estimator__max_depth': list(range(1, 10)), 'final_estimator__min_samples_split': list(range(2, 10))}\n",
    "\n",
    "search = RandomizedSearchCV(srlf, grid, n_iter=20, cv=inner_cv, scoring=score(), random_state=42)\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', result.best_params_)\n",
    "print('rmse:', np.sqrt(-result.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60149c",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "169bc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nb_hidden, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_hidden, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "act = ['relu', 'tanh']\n",
    "hidden = np.array([64, 128, 256])\n",
    "epoch = list(range(3, 10))\n",
    "NN_grid = {'activation': act, 'nb_hidden': hidden, 'epochs': epoch}\n",
    "\n",
    "NN = KerasRegressor(build_fn=create_model, batch_size=256, verbose=0, nb_hidden=64, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2847eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'activation': 'tanh', 'epochs': 9, 'nb_hidden': 256}\n",
      "rmse: 286.0403727465075\n"
     ]
    }
   ],
   "source": [
    "NN_clf = GridSearchCV(estimator=NN, param_grid=NN_grid, scoring = score(), cv=5)\n",
    "NN_pred=NN_clf.fit(X_train, y_train)\n",
    "\n",
    "print('best params: ', NN_pred.best_params_)\n",
    "print('rmse:' , np.sqrt(-NN_pred.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8a58b",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bfe837bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = cross_val_score(lr_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "knn_score = cross_val_score(knn_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "rt_score = cross_val_score(rt_clf , X=X_normalized, y=y, cv=outer_cv)\n",
    "svm_score = cross_val_score(svr_clf, X=X_normalized, y=y, cv=outer_cv)\n",
    "stack_score = cross_val_score(search, X=X_normalized, y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3f6537ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear regression': 167.67832131870085,\n",
       " 'KNN': 169.90874057134783,\n",
       " 'Regression tree': 183.30661319425926,\n",
       " 'SVR': 170.76628550096305,\n",
       " 'Stack': 167.49949605164755}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "score['linear regression'] = np.sqrt(-lr_score).mean()\n",
    "score['KNN'] = np.sqrt(-knn_score).mean()\n",
    "score['Regression tree'] = np.sqrt(-rt_score).mean()\n",
    "score['SVR'] = np.sqrt(-svm_score).mean()\n",
    "score['Stack'] = np.sqrt(-stack_score).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec181f7",
   "metadata": {},
   "source": [
    "# for task (a) vs. task (b): which models exhibit better predictive performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aec252",
   "metadata": {},
   "source": [
    "- In the scenario where you have both purchase categories, the models tend to perform better, as they can capture general trends that apply to the entire dataset.\n",
    "- When using only purchase=1 data, the models can struggle because they may overfit or fail to capture the broader distribution of spending.\n",
    "- Stacking consistently performs well, as it can adapt to the specific nuances of the data while also considering the broader patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
